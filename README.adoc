= CloudBees CI cross-region disaster recovery on Elastic Kubernetes Service using Elastic Block Store

== The Theory

CloudBees CI customers are always interested in backup and restore,
but also inquire about the possibility of link:https://en.wikipedia.org/wiki/Disaster_recovery[disaster recovery (DR)].
DR is essentially restoring from a backup after an unplanned loss of the original installation,
including across geographical regions.

AWS occasionally suffers serious outages that affect an entire region.
For more information, refer to link:https://aws.amazon.com/premiumsupport/technology/pes/[AWS Post-Event Summaries],
link:https://en.wikipedia.org/wiki/Timeline_of_Amazon_Web_Services#Amazon_Web_Services_outages[Amazon Web Services outages],
and link:https://awsmaniac.com/aws-outages/[The Complete History of AWS Outages].
To assure minimal disruption to development teams that are using CloudBees CI,
it is desirable to have a plan to restore an entire installation to a fallback region.

NOTE: For CloudBees CI running on Amazon Web Services (AWS),
some customers may find it sufficient to use multiple availability zones (AZs) within one region.
This will protect against many common outages, but may not protect against the most serious outages.
One way to do this is to use Elastic File System (EFS).

This document focuses on one important scenario:
CloudBees CI running not only on AWS, but specifically in Elastic Kubernetes Service (EKS),
using Elastic Block Store (EBS) for `$JENKINS_HOME` volumes,
and a domain managed by Route 53.
It demonstrates use of the popular OSS link:https://velero.io/[Velero] project as a backup system,
using Simple Storage Service (S3) for metadata, and EBS snapshots for the main data.

Using Kubernetes allows us to focus more on the behavior of the application and less on the infrastructure.
While it is certainly possible to fail over across regions when running CloudBees CI on traditional platforms,
more customized scripting is required to properly restore all the services and their connections.
When using a tool such as Velero on Kubernetes, not only are the data volumes backed up and restored,
but all of the metadata is backed up and restored as well.
This means that a few straightforward and portable commands allow major operations to run.

Of course, customers are free to use other open-source or commercial backup tools,
on Kubernetes or otherwise,
which are able to synchronize data across regions.
For example, link:https://cloud.google.com/gcp[Google Cloud (GCP)]
is planning a link:https://cloud.google.com/blog/products/storage-data-transfer/google-cloud-launches-backups-for-gke[native integrated backup system]
for link:https://cloud.google.com/kubernetes-engine[Google Kubernetes Engine (GKE)].

=== DR requirements for CloudBees CI

Broadly speaking, there are several requirements for cross-region DR of CloudBees CI:

* Filesystem data, such as `$JENKINS_HOME` volumes, must have been copied to the fallback region _before_ the disaster.
  After the disaster has started, it may be too late to recover data.

* Metadata, such as a list of processes, network configuration, or anything not in `$JENKINS_HOME`,
  must also have been replicated in advance.
  The primary region should be assumed to be totally inaccessible.

* There must be a simple, mostly automated way for an administrator to trigger the failover.
  (It is not required that a failover occur automatically when a problem is detected in the primary region.)

* Once restored to the fallback region, CloudBees CI must start without any serious errors from half-written files or similar.

* The failover procedure must include switching the DNS entry for CloudBees CI to the new physical location,
  so any browser bookmarks, webhooks, or similar, continue to function as they did before the restore.

* The recovery time objective (RTO) is determined by the administrator, but typically on the order of an hour or less.
  This means the failover procedure needs to complete within minutes,
  and CloudBees CI should be up and running and ready to perform builds soon afterward.

* The recovery point objective (RPO) may be longer, on the order of a day, but may also be comparable to the RTO.
  Therefore, only a few very recent builds or configuration changes may be lost.

* Since CloudBees CI does not support full high availability (HA),
  there will be a brief period where the UI is inaccessible.
  Any incoming webhooks will also be lost,
  but at least hooks coming from an SCM should be treated as an optimization;
  systems listening to hooks, such as Multibranch projects, should be configured to occasionally poll as well.

* The administrator should be shown a clear indication that a restored system is actually restored from backup,
  and given an opportunity to review any builds that may have been interrupted by the failover.
  It is not expected that such builds resume or restart automatically,
  nor is any attempt made to preserve the contents of workspaces or live process states from agents.

NOTE: CloudBees CI offers link:https://docs.cloudbees.com/docs/cloudbees-ci/latest/casc-oc/[Configuration as Code (CasC)] functionality.
An installation that has been completely converted to CasC may not need traditional backups to achieve DR;
a restore operation could consist simply of running a CasC bootstrap script in a fresh cluster.
This is only an option for a customer who has translated every significant system setting and job configuration to CasC, however.
Even then it may be desirable to perform a filesystem-level restore from backup for DR purposes,
in order to preserve transient data such as build history.

=== CloudBees CI product support for DR

CloudBees CI is compatible with DR, including across regions.
From a technical standpoint, the following major components are involved:

* Jenkins core and plugins generally keep both configuration and runtime state in a filesystem hierarchy.
  Therefore, simply copying the `$JENKINS_HOME` volume to a new location is sufficient for backup purposes.
  Wherever practical, metadata files are written atomically,
  and every effort is made to gracefully tolerate missing, truncated, or corrupted files,
  with a few exceptions for security reasons.

* Pipeline plugins are designed to allow builds to run across controller restarts.
  The same mechanisms work in backup and restore or DR scenarios
  for steps such as `input` which pause without the involvement of an agent.
  When a build is actively running on an agent inside a `node` block
  and the agent is destroyed or otherwise lost, due to a regional outage or more commonplace problems,
  it is not currently possible for the build to retry that stage on a fresh agent.
  However, the situation can at least be recorded in the build log and metadata,
  and the build can be restarted from the beginning,
  from a `checkpoint` using Scripted syntax,
  or from the start of the failed stage using Declarative syntax.

* CloudBees CI includes link:https://docs.cloudbees.com/docs/admin-resources/latest/pipelines/controlling-builds#aborted-builds[proprietary functionality] to detect a restore scenario,
  displaying a specialized notification to the administrator,
  and enumerating builds potentially or definitely affected.

Some functional improvements are available in January 2022
in the link:https://docs.cloudbees.com/docs/release-notes/latest/cloudbees-ci/modern-cloud-platforms/2.319.2.5#_feature_enhancements[CloudBees CI 2.319.2.5 release].
Other improvements and reliability fixes are planned for subsequent releases or are under consideration.

CloudBees CI on Kubernetes additionally benefits from the robust container management of the Kubernetes control plane.
Aside from the operations center and managed controllers running as ``StatefulSet``s,
controllers use the Jenkins Kubernetes plugin to schedule builds on disposable agent pods,
eliminating the need to explicitly manage worker infrastructure.
Provided that the cluster in the fallback region has sufficient capacity,
the restored installation will be ready to run new builds as soon as managed controllers start back up.
A backup does not need to include ``Pod``s,
as the operations center or managed controller pods are recreated automatically.
Agent pods cannot be restored from backup.

link:https://docs.cloudbees.com/docs/cloudbees-ci/latest/cloud-admin-guide/managing-masters#_hibernation_in_managed_masters[Hibernation of managed controllers] is also supported for DR purposes.
If only a portion of the defined managed controllers were actually running at the time of the last backup,
the same is true after the restore.
SCM webhooks delivered to the restored cluster can “wake up” hibernated managed controllers and trigger builds as usual.

=== Using Velero on AWS

Velero includes a standard plugin for AWS,
specifically based on S3 metadata storage and EBS volume snapshots.
Unfortunately, this plugin does not currently offer cross-region support.
While Velero on GCP can offer this functionality due to native cross-region Container Storage Interface (CSI) snapshots,
EBS snapshots are region-specific and must be explicitly copied.

As an example implementation for this platform,
CloudBees has developed a link:https://github.com/vmware-tanzu/velero-plugin-for-aws/pull/90[custom patch to this Velero plugin]
which implements cross-region EBS snapshot replication.
To keep RPO low,
CloudBees also developed a link:https://github.com/vmware-tanzu/velero/pull/4242[custom patch to Velero core]
to parallelize volume snapshot operations.
Backups can be restored to either the primary or failover region
and the appropriate snapshots are selected automatically at restore time.

IMPORTANT: These patches should be considered experimental and unsupported.
They are not accepted upstream by the Velero project in their current form.
General cross-region support for Velero is under discussion,
but is not expected before mid-2022 at the earliest,
as it may be based on a new link:https://github.com/vmware-tanzu/astrolabe[fundamental infrastructure].

There are a few notable limitations in the current Velero plugin patch:

* It only supports volumes in a single AZ,
  even though EKS can be configured to run stateful workloads using EBS across several AZs in the region.
  However, stateless pods such as agents could be run in a node pool in another AZ.
* It only supports one failover region, and does not implement metadata replication.
  Metadata is sent to S3 in the failover region only,
  so a restore from backup in the primary region would not work if the failover region happened to be down.

Also note that EFS has a very different snapshot and replication architecture
and is not covered by this plugin (patched or otherwise).

In combination, these patches have been tested to the scale of around 100 active managed controllers.
Hibernated managed controllers have little impact on backup time
since EBS volume snapshots, as well as cross-region snapshot replication, are incremental.
With the backup completing in just a few minutes under plausible load conditions,
a low RPO based on backups scheduled every 15 minutes can be achieved.
An RTO in the same vicinity is also possible since reconstruction of Kubernetes metadata is fairly quick.
Volumes created from EBS snapshots are loaded lazily,
so the operations center and managed controller startup time is somewhat slower than usual,
but still tolerable.

Actual results vary depending on numerous factors,
with backup performance mainly depending on the number of modified 512 KiB blocks.
Managed controllers which can modify numerous or large files,
for example by running many concurrent builds or using large log files, 
impose the most load.
CloudBees recommends that you configure link:https://docs.cloudbees.com/docs/cloudbees-ci/latest/cloud-reference-architecture/ra-for-aws/#ams3[S3-based artifact storage]
rather than storing build artifacts in `$JENKINS_HOME`.

DR-related AWS billing costs vary as well,
so customers are advised to monitor daily, weekly, or monthly cost usage graphs per “service”.
It is expected that cross-region replication of EBS snapshots
should not add significantly to the monthly bill compared to compute (EC2) costs.
Holding EBS snapshots, even within a region, incurs a noticeable cost, but still likely much less than compute costs.
However, this would be necessary for routine backup purposes anyway.
Creating an EKS cluster from scratch is time-consuming, at approximately 27 minutes, which precludes short RTOs.
In addition, this can be error-prone.
Therefore, it is advisable to keep an empty cluster—with only a control plane and the Velero service—active in the failover region, for $5 per day.
Scaling up a node pool is surprisingly much faster and seemingly reliable,
so it is reasonable to do this on demand as part of the recovery process.
This saves costs at the expense of a few minutes added to RTO.
It is also possible to use link:https://aws.amazon.com/ec2/spot/[Amazon EC2 Spot Instances] to save considerably on compute costs;
link:https://docs.aws.amazon.com/eks/latest/userguide/fargate.html[AWS Fargate] has not yet been evaluated in the context of DR.

CloudBees has also developed a link:https://github.com/cloudbees-oss/inject-metadata-velero-plugin[simple Velero plugin] that is not specific to AWS.
It records the identifier of the current restore in every `StatefulSet` as an environment variable,
so that managed controllers using the Restart Aborted Builds plugin
are alerted to the fact that a restore from a backup has occurred.

== The Practice

=== Environment details

The associated folder includes a complete, self-contained environment to see CloudBees CI running in EKS in a primary region (`us-east-1`), backed up every 15 minutes using Velero with EBS snapshots replicated to the fallback region (`us-west-1`), with the ability to restore to either the same cluster or a cluster in the fallback region on demand.

GNU make targets orchestrate terraform command to create both clusters, install CloudBees CI, and configure Velero. Also included are targets to demonstrate the backup on primary region and restore process in secondary. 

Along with the Helm chart for CloudBees CI,
link:https://docs.cloudbees.com/docs/cloudbees-ci/latest/casc-oc/[CloudBees CasC for the operations center]
is used to define most aspects of the operations center, including a randomized administrator password.
The only manual setup required is to accept a trial license for CloudBees CI when prompted.
A set of managed controllers (by default 5, but this can be overridden to test larger scales) is pre-created,
along with example Pipeline jobs on each managed controller, demonstrating behavior of various steps and simulated workloads.
Managed controllers hibernate automatically after a period of inactivity.

=== Pre-requisites 

1. Authentication to an AWS account with sufficient permissions to create such resources. This demo uses AWS profile but you could adapt the AWS provider `cbci-eks-dr-demo/modules/cb-ci-aws-eks/provider.tf` to your own needs.
2. You also need an existing Route 53 Hosted Zone to register a record for serving HTTPs traffic to CloudBees CI. It will be managed by External DNS which will point to the Alpha ALB.

=== Demo Configuration 

The configuration of the demo is centralized in the folder `env` which contains files with variables per environment and common ones.

=== Demo in Action

[source,bash]
----
$> make 
----

=== Troubleshooting

* Set `export DEBUG=true`.
* Logs for ...


